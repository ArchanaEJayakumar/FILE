A.LOGIN PAGE
Description: This code snippet is to verify the user 
credentials to ensure secure login.


<?php
session_start();
include('connection.php');
$myusername=$_POST['username']; 
$mypassword=$_POST['password']; 
$sqlss=mysqli_query($con,"SELECT * FROM reg WHERE 
username='$myusername' and password='$mypassword'");
//echo "SELECT * FROM reg WHERE 
username='$myusername' and password='$mypassword'";
$cc=mysqli_num_rows($sqlss);
if($cc==1)
{
header("location:index1.php");
}
else{
header("location:index.php?a=1");
}
?>



B.SIGN UP PAGE
Description: This code snippet is to SIGN UP in to the system



 
<?php
error_reporting(0);
?>
<html>
<head>
<meta name="viewport" content="width=device-width" 
content="initial-scale=1">
<link href="css/bootstrap.min.css" rel="stylesheet">
<link href="css/log.css" rel="stylesheet">
</head>
<body>
 <div id="p3">
 <div class="container" id="id1">
 <div class="row-justify-content-center">
 <div class="col-sm-5" style="margin-top:10px 
!important;">
 <h1><center>AUTOTRACK</center></h1><br>
 <form action="insert.php" method="POST" 
enctype="multipart/form-data">
 <div id="t1">
Name : <input type="text" name="name" required 
id="ip1" ><br>
Email : <input type="email" name="email" required 
id="ip1" ><br>
 User Name : <input type="text" name="username" 
required id="ip1" ><br>
Password : <input type="password" name="password" 
required id="ip1" ><br> </div>
 <div class="text-center"><input type="Submit" 
name="Submit" value="Submit" style="height: 40px; width: 
250px" id="p1"></div><br>
 </form>
 <form>
 <div class="text-center"><input type="Submit" 
value="Login" formaction="index.php"style="height: 40px; 
width: 250px" id="p2"></div><br>
 </form>
 </div>
 </div>
 </div>
 </div>
 </div>
</body>
</html>






CSS


body {
font: bold 11px/1.5em Verdana;
}
h1 {
font-family:Verdana, Arial, Helvetica, sans-serif;
font-size:16px;
font-weight:bold;
margin:0;
padding:0;
}hr {
border:none;
border-top:1px solid #CCCCCC;
height:1px;
margin-bottom:25px;
}
#header {
 width: 98%;
 height: 100px;
 margin-left: 15px;
 margin-right: 25px;
 margin-top: 20px;
 margin-bottom:10px;
 background: #121212;
 font-family:monospace;
 font-size:32px;
 padding-top: 55px;
 border-bottom-left-radius: 20px;
 border-bottom-right-radius: 20px;
 border-top-left-radius: 20px;
 border-top-right-radius: 20px;
 font-style: italic;
 }
#container {
 width: 1000px;
 height: auto;
 margin-left: 155px;
 margin-right: 100px;
 margin-top: 25px; border-colour: #121212;
 border-width: 1px;
 border-style: solid;
 border-top-left-radius: 20px;
 border-top-right-radius: 20px;
 border-bottom-left-radius: 20px;
 border-bottom-right-radius: 20px;
 }
.contents{
 padding-top: 40px;
 padding-left: 40px;
 padding-right: 20px;
 padding-bottom: 40px;
 font-family: monospace;
 font-size: 14px;
 }
 
 
/*input[type="file"]{
 width: 240px;
 height: 38px;
 font-family:Arial, "Helvetica", sans-serif;
 font-size:12px;
 font-weight:bold;
 colour:#000;
 text-decoration:none;
 text-transform:uppercase;
 text-align:center;
 text-shadow:1px 1px 0px #37a69b;
 padding-top:6px;
 padding-bottom:3px; margin-left: 10px;
 position:relative;
 cursor:pointer;
 border: none; 
 border-top-left-radius: 5px;
 border-top-right-radius: 5px;
 border-bottom-right-radius: 5px;
 border-bottom-left-radius:5px;
 }*/
input[type="submit"],[type="reset"]{
 width:240px;
 height:35px;
 display:block;
 font-family:Arial, "Helvetica", sans-serif;
 font-size:12px;
 font-weight:bold;
 colour:#fff;
 text-decoration:none;
 text-transform:uppercase;
 text-align:center;
 text-shadow:1px 1px 0px #37a69b;
 padding-top:6px;
 position:relative;
 cursor:pointer;
 border: none; 
 background-colour: #121212;
 
 border-top-left-radius: 5px;
 border-top-right-radius: 5px;
 border-bottom-right-radius: 5px;
 border-bottom-left-radius:5px;}
input[type="submit"]:active {
 top:3px;
 box-shadow: inset 0px 1px 0px #2ab7ec, 0px 2px 0px 0px 
#31524d, 0px 5px 3px #999;
}
input[type="text"],select, textarea, [type="number"], 
[type="password"], [type="file"]{
 border: 1px solid #78AB46;
 border-radius: 4px;
 box-shadow: 0 1px #fff;
 box-sizing: border-box;
 colour: #696969;
 height: 39px;
 //margin: 31px 0 0 29px;
 padding-left: 37px;
 transition: box-shadow 0.3s;
 width: 240px;
}
input[type="text"]:focus {
 box-shadow: 0 0 4px 1px rgba(55, 166, 155, 0.3);
 outline: 0;
}
input[type="password"]:focus {
 box-shadow: 0 0 4px 1px rgba(55, 166, 155, 0.3);
 outline: 0;
}
#tabs {
float:left;
width:100%;//background:#EFF4FA;
 background: #FFFFFF;
font-size:93%;
line-height:normal;
border-bottom:1px solid #121212;
}
#tabs ul {
margin:0;
padding:10px 10px 0 50px;
list-style:none;
}
#tabs li {
display:inline;
margin:0;
padding:0;
}
#tabs a {
float:left;
background:url("tableft.gif") no-repeat left top;
margin:0;
padding:0 0 0 5px;
text-decoration:none;
}
#tabs a span {
float:left;
display:block;
background:url("tabright.gif") no-repeat right top;padding:5px 15px 4px 6px;
colour:#FFF;
}
/* Commented Backslash Hack hides rule from IE5-Mac \*/
#tabs a span {float:none;}
/* End IE5-Mac hack */
#tabs a:hover span {
colour:#FFF;
}
#tabs a:hover {
background-position:0% -42px;
}
#tabs a:hover span {
background-position:100% -42px;
}
#c{
display:inline-block; 
 display: inline; 
 margin-right:10px; 
}




C.INPUT PAGE
Description: This code snippet is to give inputs like model,



colour and license in to the system.
<?php$target_path = "uploads/";
$target_path = $target_path . basename( 
$_FILES['uploadedfile']['name']); 
$myFile ="input.txt";
$fh = fopen($myFile,'w') or die("can't open file");
fwrite($fh,$target_path);
fclose($fh);
$data=$_POST['model'].",".$_POST['colour'];
$myFile ="colour.txt";
$fh = fopen($myFile,'w') or die("can't open file");
fwrite($fh,$data);
fclose($fh);
if(move_uploaded_file($_FILES['uploadedfile']['tmp_name'], 
$target_path)) {
$python=`python car_model_detectionn.py`;
header("location:index1.php");
 
} else{
 echo "There was an error uploading the file, please try 
again!";
}
?>



D.UPLOAD AND DETECTION PAGE
Description: This code snippet is to upload the video file 
and to detect the vehicle in system.
MODEL DETECTIONDescription: This code is to detect the model of the 
vehicle from the input video file.



import glob
import random
# Load Yolo
net = cv2.dnn.readNet("yolov3_custom_last.weights", 
"yolov3_custom.cfg")
# Name custom object
classes = []
with open("classes.names", "r") as f:
 classes = [line.strip() for line in f.readlines()]
layer_names = net.getLayerNames()
output_layers = [layer_names[i[0] - 1] for i in 
net.getUnconnectedOutLayers()]
colours = np.random.uniform(0, 255, size=(len(classes), 
3))
# Images path
#images_path = 
glob.glob(r"F:\aumento_test\apple\apple_testing\*.png")
# Insert here the path of your images
#random.shuffle(images_path)
cap = cv2.VideoCapture('1_1.mp4')
# loop through all the images
#for img_path in images_path:
while(cap.isOpened()):
 # Loading image
 #img = cv2.imread(img_path)
 ret, frame = cap.read()
 if (ret!=True):
 break
 img=frame
 img = cv2.resize(img, None, fx=0.4, fy=0.4)
 height, width, channels = img.shape # Detecting objects
 blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 
416), (0, 0, 0), True, crop=False)
 print("First Blob: {}".format(blob.shape))
 net.setInput(blob)
 outs = net.forward(output_layers)
 # Showing informations on the screen
 class_ids = []
 confidences = []
 boxes = []
 for out in outs:
 for detection in out:
 scores = detection[5:]
 #class_id = np.argmax(scores)
# sort the probabilities (in descending) order, grab the 
index of the
# top predicted label, and draw it on the input image
 class_id = np.argsort(scores)[::-1][0]
 confidence = scores[class_id]
 if confidence > 0.5:
 # Object detected
 print(class_id)
 center_x = int(detection[0] * width)
 center_y = int(detection[1] * height)
 w = int(detection[2] * width)
 h = int(detection[3] * height)
 # Rectangle coordinates
 x = int(center_x - w / 2)
 y = int(center_y - h / 2)
 boxes.append([x, y, w, h])
 confidences.append(float(confidence))
 class_ids.append(class_id)
 indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 
0.4)
 print(indexes)
 #font = cv2.FONT_HERSHEY_PLAIN
 font = cv2.FONT_ITALIC
 for i in range(len(boxes)):
 if i in indexes: x, y, w, h = boxes[i]
 label = str(classes[class_ids[i]])
 print(label)
 colour1 = colours[class_ids[i]]
 colour=(255,0,0)
 cv2.rectangle(img, (x, y), (x + w, y + h), 
colour, 2)
 cv2.putText(img, label, (x, y + 30), font, 
0.5, colour, 2)
 cv2.imshow("Image", img)
 #key = cv2.waitKey(0)
 if cv2.waitKey(1) & 0xFF == ord('q'):
 break
cv2.destroyAllWindows()
cap.release()




COLOUR DETECTION
Description: This code snippet is for detecting the 
colour and model of the vehicle.




import cv2
import numpy as np
import pandas as pd
import glob
import random
# Load Yolo
net = cv2.dnn.readNet("yolov3_custom_last.weights",
"yolov3_custom.cfg")
classes = []
with open("classes.names", "r") as f:
 classes = [line.strip() for line in f.readlines()]
layer_names = net.getLayerNames()
output_layers = [layer_names[i[0] - 1] for i in 
net.getUnconnectedOutLayers()]
colours = np.random.uniform(0, 255, size=(len(classes), 
3))
cap = cv2.VideoCapture('4.mp4')
#save video
frame_width = int(cap.get(3))
frame_height = int(cap.get(4))size1 = (frame_width, frame_height)
result = 
cv2.VideoWriter('out.avi',cv2.VideoWriter_fourcc(*'MJPG'
),10, size1)
# Images path
#images_path = 
glob.glob(r"F:\aumento_test\bavan_sir_mail\car_colour\*.
png")
#random.shuffle(images_path)
#for img_path in images_path:
# Loading image
while True:
 #img = cv2.imread(img_path)
 ret, frame = cap.read()
 if (ret!=True):
 break
 img=frame
# Insert here the path of your images
# Loading image
#img = cv2.imread("5.png")
 img = cv2.resize(img, None, fx=0.4, fy=0.4)
 height, width, channels = img.shape
# Detecting objects
 blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 
416), (0, 0, 0), True, crop=False)
 net.setInput(blob)
 outs = net.forward(output_layers)
# Showing informations on the screen
 class_ids = []
 confidences = []
 boxes = []
 for out in outs:
 for detection in out:
 scores = detection[5:]
 class_id = np.argmax(scores)
 confidence = scores[class_id]
 if confidence > 0.5:
 # Object detected
 center_x = int(detection[0] * width) center_y = int(detection[1] * height)
 w = int(detection[2] * width)
 h = int(detection[3] * height)
 # Rectangle coordinates
 x = int(center_x - w / 2)
 y = int(center_y - h / 2)
 boxes.append([x, y, w, h])
 confidences.append(float(confidence))
 class_ids.append(class_id)
 indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 
0.4)
 #print(indexes)
 font = cv2.FONT_ITALIC
 get_colour="processing"
 for i in range(len(boxes)):
 if i in indexes:
 x, y, w, h = boxes[i]
 label = str(classes[class_ids[i]])
 colour = colours[class_ids[i]]
 print (label)
 
 
 #ROI = img[(y-h):(y+h), (x-w):(x+w)]
 ROI = img[y:y+h, x:x+w]
 
 if ROI is None:
 get_colour="processing"
 
 else:
 
 #cv2.imshow("cropped", ROI)
 hsvFrame = cv2.cvtColour(ROI, 
cv2.COLOUR_BGR2HSV)
 
 # Set range for red colour and 
 # define mask
 red_lower = np.array([136, 87, 111], 
np.uint8)
 red_upper = np.array([180, 255, 255], 
np.uint8)red_mask = cv2.inRange(hsvFrame, 
red_lower, red_upper)
 # Set range for white colour and
 # define mask
 white_lower = np.array([94, 80, 2], 
np.uint8)
 white_upper = np.array([120, 255, 255], 
np.uint8)
 white_mask = cv2.inRange(hsvFrame, 
white_lower, white_upper)
 
 # Set range for black colour and 
 # define mask
 black_lower = np.array([0, 0, 0], 
np.uint8)
 black_upper = np.array([110, 255, 30], 
np.uint8)
 black_mask = 
cv2.inRange(hsvFrame,black_lower, black_upper)
 
 # Morphological Transform, Dilation
 # for each colour and bitwise_and operator
 # between imageFrame and mask determines
 # to detect only that particular colour
 kernal = np.ones((5, 5), "uint8")
 
 # For red colour
 red_mask = cv2.dilate(red_mask, kernal)
 res_red = cv2.bitwise_and(ROI,ROI,mask = 
red_mask)
 
 # For white colour
 white_mask = cv2.dilate(white_mask, 
kernal)
 res_white = cv2.bitwise_and(ROI, 
ROI,mask = white_mask)
 
 # For grey colour
 black_mask = cv2.dilate(black_mask, 
kernal)
 res_black = cv2.bitwise_and(ROI, 
ROI,mask = black_mask)
# Creating contour to track red colour
 contours, hierarchy = 
cv2.findContours(red_mask,cv2.RETR_TREE,cv2.CHAIN_APPROX
_SIMPLE)
 for pic, contour in enumerate(contours):
 area = cv2.contourArea(contour)
if(area > 300):
 get_colour="red"
 
 # Creating contour to track white colour
 contours, hierarchy = 
cv2.findContours(white_mask,cv2.RETR_TREE,cv2.CHAIN_APPR
OX_SIMPLE)
 for pic, contour in enumerate(contours):
 area = cv2.contourArea(contour)
if(area > 500):
 get_colour="black"
 
 # Creating contour to track black colour
 contours, hierarchy = 
cv2.findContours(black_mask,cv2.RETR_TREE,cv2.CHAIN_APPR
OX_SIMPLE)
 for pic, contour in enumerate(contours):
 area = cv2.contourArea(contour)
if(area > 300):
 get_colour="white" 
 
 #text = get_colour+',' + label
 print(get_colour)
 text = label+' ,' +get_colour
 cv2.rectangle(img, (x, y), (x + w, y + 
h),(255,0,0), 2)
 #cv2.putText(img,label, (x, y + 30), font, 
0.5, (255,0,0), 1)
 #cv2.putText(img,text, (x, y + 30), font, 
0.5, (255,0,0), 1)
#cv2.putText(img,text,start,font(0-
7),fontScale,colour,thickness,lineType )
 cv2.putText(img, 
text,(50,50),2,0.8,(255,0,0),1,cv2.LINE_AA)
#print ("Total person count in the image is " + str 
(personCount))
 result.write(img) cv2.imshow("Image", img)
 if cv2.waitKey(1) & 0xFF == ord('q'):
 break
cv2.destroyAllWindows()
cap.release()


LICENSE NUMBER DETECTION
Description: This code snippet is used for detecting 
the license number of the vehicle.



import numpy as np
import cv2
from copy import deepcopy
from PIL import Image
import pytesseract as tess
import os
def preprocess(img):
#cv2.imshow("Input",img)
imgBlurred = cv2.GaussianBlur(img, (5,5), 0)
gray = cv2.cvtColour(imgBlurred, 
cv2.COLOUR_BGR2GRAY)
sobelx = cv2.Sobel(gray,cv2.CV_8U,1,0,ksize=3)
ret2,threshold_img = 
cv2.threshold(sobelx,0,255,cv2.THRESH_BINARY+cv2.THRESH_
OTSU)
return threshold_img
def cleanPlate(plate):
gray = cv2.cvtColour(plate, cv2.COLOUR_BGR2GRAY)
_, thresh = cv2.threshold(gray, 150, 255, 
cv2.THRESH_BINARY)
contours,hierarchy = 
cv2.findContours(thresh.copy(),cv2.RETR_EXTERNAL, 
cv2.CHAIN_APPROX_NONE)
if contours:
areas = [cv2.contourArea(c) for c in contours]
max_index = np.argmax(areas)
max_cnt = contours[max_index]
max_cntArea = areas[max_index]
x,y,w,h = cv2.boundingRect(max_cnt)if not ratioCheck(max_cntArea,w,h):
return plate,None
cleaned_final = thresh[y:y+h, x:x+w]
return cleaned_final,[x,y,w,h]
else:
return plate,None
def extract_contours(threshold_img):
element = 
cv2.getStructuringElement(shape=cv2.MORPH_RECT, 
ksize=(17, 3))
morph_img_threshold = threshold_img.copy()
cv2.morphologyEx(src=threshold_img, 
op=cv2.MORPH_CLOSE, kernel=element, 
dst=morph_img_threshold)
contours, hierarchy= 
cv2.findContours(morph_img_threshold,mode=cv2.RETR_EXTER
NAL,method=cv2.CHAIN_APPROX_NONE)
return contours
def ratioCheck(area, width, height):
ratio = float(width) / float(height)
if ratio < 1:
ratio = 1 / ratio
aspect = 4.7272
min = 15*aspect*15 
max = 125*aspect*125 
rmin = 3
rmax = 6
if (area < min or area > max) or (ratio < rmin or 
ratio > rmax):
return False
return True
def isMaxWhite(plate):
avg = np.mean(plate)
if(avg>=115):return True
else:
return False
def validateRotationAndRatio(rect):
(x, y), (width, height), rect_angle = rect
if(width>height):
angle = -rect_angle
else:
angle = 90 + rect_angle
if angle>15:
return False
if height == 0 or width == 0:
return False
area = height*width
if not ratioCheck(area,width,height):
return False
else:
return True
def cleanAndRead(img,contours):
for i,cnt in enumerate(contours):
min_rect = cv2.minAreaRect(cnt)
if validateRotationAndRatio(min_rect):
x,y,w,h = cv2.boundingRect(cnt)
plate_img = img[y:y+h,x:x+w]
if(isMaxWhite(plate_img)):
clean_plate, rect = 
cleanPlate(plate_img)
if rect:
x1,y1,w1,h1 = rect
x,y,w,h = x+x1,y+y1,w1,h1
#cv2.imshow("Cleaned 
Plate",clean_plate)
#cv2.waitKey(0)
plate_im = 
Image.fromarray(clean_plate)text = 
tess.image_to_string(plate_im, lang='eng')
#print ("Detected Text : 
",text)
font = cv2.FONT_HERSHEY_SIMPLEX
bottomLeftCornerOfText = (x,y10)
fontScale = 1
fontColour = (240,68,83)
lineType = 2
img = 
cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
cv2.putText(img,text,bottomLeftCornerOfText, font, 
fontScale, fontColour, lineType)
cv2.imshow("Detected 
Plate",img)
cv2.waitKey(1)
return img
if __name__ == '__main__':
vid = cv2.VideoCapture('test1.mp4')
while(True):
ret, im = vid.read()
if ret:
threshold_img = preprocess(im)
contours= extract_contours(threshold_img)
cleanAndRead(im,contours)
#cv2.imshow('frame', img)
if cv2.waitKey(33) & 0xFF == ord('q'):
break
vid.release()
cv2.destroyAllWindows()